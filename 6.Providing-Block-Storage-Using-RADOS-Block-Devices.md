# 管理RADOS块设备

## 基于RBD的块存储

块设备是服务器、笔记本电脑和其他计算系统最常见的长期存储设备。它们将数据存储在固定大小的块中。块设备包括基于旋转磁碟的硬盘驱动器和基于非易失性存储器的固态驱动器。要使用存储，请使用文件系统格式化块设备，并将其挂载到Linux文件系统层次结构上

RBD (RADOS Block Device)特性提供来自Red Hat Ceph存储集群的块存储。RADOS在Red Hat Ceph存储集群的池中提供了存储为RBD映像的虚拟块设备

## 管理和配置RBD镜像

作为存储管理员，可以使用rbd命令创建、列表、检索块设备镜像信息、调整大小和移除块设备镜像。创建RBD镜像的示例如下:

1. 确保rbd映像的rbd池(或自定义池)存在。使用ceph osd pool create命令创建RBD镜像池。创建完成后，需要使用rbd pool init命令对其进行初始化

2. 虽然Ceph管理员可以访问池，但Red Hat建议您使用Ceph auth命令为客户端创建一个更受限制的Cephx用户。授予用户只对需要的RBD池进行读写访问，而不是访问整个集群

3. 使用RBD Create - -size size pooI-name/image-name命令创建RBD镜像。如果不指定存储池名称，则使用默认的存储池名称

rbd_defaultlt_pool参数指定用于存储RBD映像的默认池的名称。使用ceph config set osd rbd_default pool value设置该参数

## 访问RADOS块设备存储

内核RBD客户端(krbd)将RBD映像映射到Linux块设备。librbd库为KVM虚拟机和OpenStack云实例提供RBD存储。这些客户机允许裸机服务器或虚拟机使用RBD映像作为普通的基于块的存储。在OpenStack环境中，OpenStack将这些RBD映像附加并映射到Linux服务器，它们可以作为启动设备。Red Hat Ceph Storage 将虚拟块设备使用的实际存储分散到整个集群中，通过IP网络提供高性能访问

### 使用RBD内核客户端访问Ceph存储

Ceph客户端可以使用本地Linux内核模块krbd挂载RBD映像。这个模块将RBD映像映射到名称为/dev/rbd0的Linux块设备

![](https://gitee.com/cnlxh/ceph/raw/master/images/block/devices-access-rbd-kernel.svg)

rbd device map命令使用krbd内核模块来映射一个image。rbd map命令是rbd device map命令的缩写。rbd device unmap (rbd unmap)命令使用krbd内核模块解除映射的镜像。将RBD池中的test RBD镜像映射到客户端主机上的/dev/rbd0设备

```bash
[root@node ~]# rbd map rbd/test 
/dev/rbd0 
```

Ceph客户端系统可以像其他块设备一样使用映射的块设备(在示例中称为/dev/rbd0)。可以使用文件系统对其进行格式化、挂载和卸载

两个客户端可以同时将同一个RBD映像映射为一个块设备。这对于备用服务器的高可用性集群非常有用，但是Red Hat建议当块设备包含一个普通的单挂载文件系统时，一次将一个块设备附加到一个客户机上。同时在两个或多个客户机上挂载包含普通文件系统(如XFS)的RADOS块设备可能会导致文件系统损坏和数据丢失

rbd device list命令，缩写为rbd showmapped，用来列出机器上映射的rbd映像

```bash
[root@node -)# rbd showmapped 
id pool namespace image snap device
0  rbd             test  -    /dev/rbd0
```

rbd device unmap命令，缩写为rbd unmap，用于从客户端机器上解除rbd映像的映射

```bash
[root@node ~]# rbd unmap /dev/rbd0
```

rbd map和rbd unmap命令需要root权限

### 持久化映射RBD图像

rbdmap服务可以在启动和关闭系统时自动将RBD映像映射和解除映射到设备。/etc/ceph/rbdmap中查找具有其凭证的映射图像，服务使用它们在/etc/fstab文件中显示的挂载点来挂载和卸载RBD映像

以下步骤将rbdmap配置为持久化映射和解除映射一个已经包含文件系统的RBD映像:

1. 为文件系统创建挂载点

2. 在/etc/ceph/rbdmap RBD映射文件中创建一个单行条目。这个条目必须指定RBD池和映像的名称。它还必须引用具有读写权限的Cephx用户来访问映像和相应的密钥环文件。确保客户端系统上存在用于Cephx用户的key-ring文件

3.在客户端系统的/etc/fstab文件中为RBD创建一个条目。块设备的名称形式如下:

```bash
/dev/rbd/pool_name/image_name
```

指定noauto挂载选项，因为处理文件系统挂载的是rbdmap服务，而不是Linux fstab例程

4. 确认块设备映射成功。使用rbdmap map命令挂载设备。使用rbdmap unmap命令卸载

5. 启用rbdmap systemd服务，有关更多信息，请参阅rbdmap(8)

### 使用基于librbd的客户端访问Ceph存储

librbd库为用户空间应用程序提供了对RBD映像的直接访问。它继承了librados将数据块映射到Ceph对象存储中的对象的能力，并实现了访问RBD映像以及创建快照和克隆的能力

云和虚拟化解决方案，如OpenStack和libvirt，使用librbd将RBD映像作为块设备提供给云实例和它们管理的虚拟机。例如，RBD映像可以存储QEMU虚拟机映像。使用RBD克隆特性，虚拟容器可以在不复制引导映像的情况下引导虚拟机。当写入克隆内未分配的对象时，copy-on-write (COW)机制将数据从父复制到克隆。读取时复制(COR)机制从克隆内未分配的对象读取数据时，将数据从父克隆复制到克隆

![](https://gitee.com/cnlxh/ceph/raw/master/images/block/devices-access-rbd-vm.svg)

因为Ceph块设备的用户空间实现(例如，librbd)不能利用Linux页面缓存，所以它执行自己的内存缓存，称为RBD缓存。RBD缓存的行为与Linux)页面缓存的方式类似。当OS实现一个barrier机制或一个flush请求时，Ceph将所有脏数据写入osd。这意味着使用回写缓存与在虚拟机中使用物理硬盘缓存(例如，Linux内核>= 2.6.32)一样安全。缓存使用最近最少使用(LRU)算法，在回写模式下，它可以合并连续的请求以获得更好的吞吐量

RBD缓存对于客户机来说是本地的，因为它使用发起I/O请求的机器上的RAM。例如，如果你的redhat OpenStack平台安装的Nova计算节点使用librbd作为虚拟机，OpenStack客户端启动I/O请求将使用本地RAM作为RBD缓存

#### RBD缓存配置

**缓存未启用**

读取和写入到Ceph对象存储。Ceph集群在所有相关OSD日志上写入和刷新数据时承认写入操作。

**缓存启用(回写式)**

考虑两个值，未刷新的缓存字节数U和最大脏缓存字节数M，当U < M时，或者在将数据写回磁盘直到U < M时，才承认写操作

**直写式高速缓存**

将最大脏字节设置为O以强制透写模式。Ceph集群在所有相关OSD日志上写入和刷新数据时承认写入操作

如果使用回写模式，那么当librbd库将数据写入服务器的本地缓存时，它会缓存并承认I/O请求。考虑对战略生产服务器进行透写，以减少服务器故障时数据丢失或文件系统损坏的风险。Red Hat Ceph Storage提供了以下一组RBD缓存参数:

| 参数                                 | 描述                           | 默认    |
| ---------------------------------- | ---------------------------- | ----- |
| rbd_cache                          | 启用RBD缓存，Value=true I false   | true  |
| rbd_cache_size                     | 每个RBD的缓存大小，单位为字节             | 32 MB |
| rbd_cache_ max_dirty               | 每个RBD映像允许的最大脏字节              | 24 MB |
| rbd_cache_target_dirty             | 每个RBD镜像启动抢占式刷写的脏字节           | 16 MB |
| rbd_cache_max_dirty_age            | 刷写前的最大页寿命(以秒为单位)             | 1     |
| rbd_cache_writethrough_until_flush | 从write-through模式开始，直到执行第一次刷新 | true  |

分别执行ceph config set client parameter value命令或ceph config set global parameter value命令

使用librbd时，需要为OpenStack Cinder、Nova和Glance分别创建单独的Cephx用户名。通过遵循推荐的实践，您可以根据Red Hat OpenStack平台环境访问的RBD映像类型创建不同的缓存策略

## 调整RBD镜像格式

RBD镜像在对象上条带化，并存储在RADOS对象存储中。Red Hat Ceph Storage提供了定义这些镜像如何条纹化的参数

### RADOS块设备镜像布局

RBD镜像中的所有对象都有一个名称，以每个RBD镜像的“RBD Block name Prefix”字段的值开头，通过RBD info命令显示。在这个前缀之后，有一个句点(.)，后面跟着对象编号。对象编号字段的值是一个12个字符的十六进制数

```bash
[root@node ~]# rbd info rbdimage 
rbd image ' rbdimage ': 
size 10240{nbsp}MB in 2560 objects 
order 22 (4 MiB objects) 
snapshot_ count: 0 
id: 867cba5c2d68 
block_name_prefix: rbd_data.867cba5c2d68 
format: 2 
features: layering, exclusive-lock, object-map, fast-diff, deep-flatten 
```

```bash
[root@node -]# rados -p rbd ls 
rbd_object_map . d3d0d7d0b79e . 0000000000000008 
rbd_id. rbdimage 
rbd_object_map . d42cle0al883 
rbd_directory 
rbd_children 
rbd_info 
rbd_header. d3d0d7d0b79e 
rbd_header. d42cle0al883 
rbd_object_map . d3d0d7d0b79e 
rbd_trash 
```

Ceph块设备支持在一个红帽Ceph存储集群内的多个OSD上条带化存储数据

![](https://gitee.com/cnlxh/ceph/raw/master/images/block/devices-rbd-layout.svg)

### RBD镜像顺序

镜像顺序是RBD镜像中使用的对象的大小。镜像顺序基于<<(bitwise left shift)C操作符定义一个二值移位值。该操作符将左操作数位移位右操作数值。例如:1 << 2 = 4。十进制1是二进制的0001，因此1 << 2 = 4运算的结果是二进制的0100，即十进制的4。镜像顺序的值必须在12到25之间，其中12 = 4 KiB, 13 = 8 KiB。为例。默认镜像顺序为22，产生4个MiB节点。可以使用rbd create命令的--order选项来覆盖缺省值

你可以用--object-size选项指定对象的大小。该参数指定的对象大小必须在4096 (4kib) ~ 33,554,432 (32mib)之间，单位为字节/ K或M(如4096、8k或4m)

### RBD镜像格式

每个RBD镜像都有三个相关参数:

**image_format** RBD镜像格式版本。默认值为2，即最新版本。版本1已被弃用，不支持克隆和镜像等特性

**stripe_unit** 一个对象中存储的连续字节数，默认为object_size。

**stripe_count** 条带跨越的RBD映像对象数目，默认为1

对于RBD格式2镜像，可以更改每个参数的值。设置必须与下列等式对齐:

```bash
stripe_unit * stripe_count = object_size
```

For example:

```bash
stripe_unit = 1048576, stripe_count = 4 for default 4 MiB objects
```

记住object_size必须不小于4096字节，且不大于33,554,432字节。当你创建RBD映像时，使用--object-size选项指定这个值。缺省情况下，节点大小为4192304字节(4mib)

# 管理RADOS块设备快照

## 启用RBD快照和克隆功能

使用RBD格式2的镜像支持几个可选特性。请使用rbd feature enable或rbd feature disable命令开启或关闭rbd镜像特性。这个例子在rbd池中的测试图像上启用了分层特性

```bash
[root@node ~]# rbd feature enable rbd/test layering 
```

禁用分层特性，使用rbd feature disable命令:

```bash
[root@node ~]# rbd feature disable rbd/test layering
```

这些是RBD镜像的一些可用特性;

| 名称             | 描述                                          |
| -------------- | ------------------------------------------- |
| layering       | 分层支持以启用克隆                                   |
| striping       | Striping v2支持增强性能，用librbd支持                 |
| exclusive-lock | 独占锁定的支持                                     |
| object-map     | 对象映射支持(需要独占锁)                               |
| fast-diff      | 快速diff命令支持(需要object-map AND exclusive-lock) |
| deep-flatten   | 扁平化RBD映像的所有快照                               |
| journaling     | 日志记录                                        |
| data- pool     | EC数据池支持                                     |

## RBD 快照

RBD快照是在特定时间创建的RBD映像的只读副本。RBD快照使用COW技术来减少维护快照所需的存储空间。当集群对RBD快照镜像发起写I/O请求时，需要先将原始数据复制到该RBD快照镜像所在位置组的其他区域。快照在创建时不消耗任何存储空间，而是随着它们所包含的对象的大小而增长改变。RBD映像支持增量快照

在创建快照之前，使用fsfreeze命令暂停对文件系统的访问。fsfreeze --freeze命令停止对文件系统的访问，并在磁盘上创建一个稳定的映像。当文件系统未冻结时，不要进行文件系统快照，因为这会破坏快照的文件系统。快照完成后，使用fsfreeze - -unfreeze命令恢复对文件系统的操作和访问

![](https://gitee.com/cnlxh/ceph/raw/master/images/block/device-snapshot01.svg)

快照COW过程在对象级别操作，与RBD映像的写I/O请求的大小无关。如果您向具有快照的RBD映像写入单个字节，那么Ceph将整个受影响的对象从RBD映像复制到快照区域

![](https://gitee.com/cnlxh/ceph/raw/master/images/block/device-snapshot02.svg)

如果RBD镜像存在快照，则删除RBD镜像失败。使用rbd snap purge命令删除快照

使用rbd snap create命令创建Ceph设备的快照

```bash
[root@node ~]# rbd snap create pool/image@firstsnap 
creating snap: 100% complete ... done.
```

使用rbd snap ls命令列出块设备快照

```bash
[root@node -]# rbd snap ls pool/image 
SNAPID NAME         SIZE         PROTECTED TIMESTAMP 
4     firstsnap     128 MiB     Thu Oct 14 16:55:01 2021 
7     secondsnap    128 MiB     Thu Oct 14 17:48:59 2021 
```

rbd snap rollback命令用于回滚块设备快照，快照中的数据将覆盖当前镜像版本

```bash
[root@node ~]# rbd snap rollback pool/image@firstsnap 
SNAPID     NAME         SIZE     PROTECTED TIMESTAMP 
4         firstsnap     128 MiB  Thu Oct 14 16:55:01 2021 
7         secondsnap    128 MiB  Thu Oct 14 17:48:59 2021 

```

使用rbd snap rm命令删除Ceph块设备的快照

```bash
[root@node ~]# rbd snap rm pool/image@secondsnap 
Removing snap: 100% complete ... done
```

## RBD 克隆

RBD克隆是以RBD受保护快照为基础的RBD镜像的读写副本。RBD克隆也可以被扁平化，这可以将其转换为独立于源的RBD映像。克隆过程有三个步骤:

1. 创建一个快照
   
   ```bash
   [root@node ~]# rbd snap create poollimage@snapshot 
   Creating snap: 100% complete ... done.
   ```

2. 保护快照不被删除
   
   ```bash
   [root@node ~]# rbd snap protect pool/image@snapshot 
   ```

3. 使用受保护快照创建克隆
   
   ```bash
   [root@node ~]# rbd clone poollimagename@snapshotname poollclonename 
   ```

新创建的克隆的行为就像一个常规的RBD映像。克隆支持COW和COR，默认为COW。COW向克隆应用写I/O请求之前，先将父快照数据拷贝到克隆中

![](https://gitee.com/cnlxh/ceph/raw/master/images/block/device-clone01.svg)

可以因此启用COR支持RBD克隆。与父RBD快照和克隆快照相同的数据直接从父RBD快照读取。如果父节点的osd相对于客户端有较高的延迟，这可能会使读取更昂贵。COR将对象第一次读取时复制到克隆

如果启用了COR, Ceph会在处理读I/O请求之前将数据从父快照复制到克隆中，如果数据还没有出现在克隆中。通过运行ceph config set client rbd_c lone_copy_on_read true命令或ceph config set global rbd_clone_copy_on_read true命令来激活COR特性，不覆盖原始数据

如果在RBD克隆上禁用了COR，克隆不能满足的每一个读操作都会向克隆的父节点发出I/O请求

![](https://gitee.com/cnlxh/ceph/raw/master/images/block/device-clone02.svg)

克隆COW和COR过程在对象级操作，不管请求大小是I/O。要读取或写入RBD克隆的单个字节，Ceph将整个对象从父映像或快照复制到克隆中

使用rbd命令管理rbd克隆

| 命令                                                                        | 描述    |
| ------------------------------------------------------------------------- | ----- |
| rbd children [pool-name/]image-name@snapshot-name                         | 列出克隆  |
| rbd clone [pool-name/]parent-image@snap-name [pool-name/]child-image-name | 创建克隆  |
| rbd flatten [pool-namel]child-image-name                                  | 扁平化克隆 |

当扁平化一个克隆时，Ceph将所有缺失的数据从父副本复制到克隆中，然后删除对父副本的引用。克隆将成为一个独立的RBD映像，并且不再是受保护快照的子快照

不能直接从池中删除RBD映像。相反，使用rbd trash mv命令将映像从池中移动到垃圾中。使用rbd trash rm命令从垃圾中删除对象。可以将克隆正在使用的活动映像移动到垃圾中，以便稍后删除

# 导入和导出RBD镜像

## 导入和导出RBD镜像

RBD导出和导入机制允许维护RBD映像的可操作副本，在同一个集群中或通过使用单独的集群实现功能完整且可访问的。可以将这些副本用于各种用例，包括:

1. 使用真实的数据量测试新版本

2. 使用真实的数据量运行质量保证流程

3. 使用真实的数据量实现业务连续性场景

4. 将备份流程与生产块设备解耦

RADOS块设备特性提供了导出和导入整个RBD映像或仅RBD映像在两个时间点之间变化的能力

### 导出RBD镜像

Red Hat Ceph Storage提供了rbd export命令来导出rbd镜像到文件中。该命令将RBD镜像或RBD镜像快照导出到指定的目标文件中。rbd export命令的语法如下:

```bash
rbd export [--export-format {1|2}) (image-spec | snap-spec) [dest-path] 
```

--export-format选项指定导出数据的格式，允许将较早的RBD格式1镜像转换为较新的格式2镜像。下面的示例将一个名为test的RBD映像导出到/tmp/test.dat文件

```bash
[ceph: root@node /]# rbd export rbd/test /tmp/test.dat
```

### 导入RBD镜像

Red Hat Ceph Storage提供了rbd import命令，用于从文件中导入rbd镜像。该命令创建一个新映像，并从指定的源路径导入数据。rbd import命令的语法如下:

```bash
rbd import [--export-format {1|2}] [--image-format format-id] [--object-size size-in-B/K/M] [--stripe-unit size-in-B/K/M --stripe-count num] [--image-feature feature-name) ... [--image-shared] src-path [image-spec]
```

--export -format选项指定导入数据的数据格式。当导入format 2导出的数据时，使用- -stripe-unit， -- stripe-count， --object-size和- -image-feature选项创建新的RBD format 2 image

--export-format参数值必须与相关rbd匹配RBD导入命令

## 导出和导入RBD镜像的变化

Red Hat Ceph Storage提供rbd export-diff和rbd import-diff命令来导出和导入rbd镜像上两个时间点之间的更改。语法与rbd export、rbd import命令相同

时间端点可以是:

1. RBD镜像的当前内容，如poolname/imagename

2. RBD镜像的快照，例如poolname/imagename@snapname

开始时间包括:

1. RBD映像的创建日期和时间。例如，不使用- -from- snap选项

2. RBD镜像的快照，例如使用--from-snap snapname选项获取

如果指定了起始点快照，该命令将在创建该快照后导出所做的更改，如果不指定快照，该命令将导出自创建以来的所有更改RBD镜像，与常规的RBD镜像导出操作相同

import-diff操作执行以下有效性检查:

1. 如果export-diff是相对于一个开始快照，那么这个快照也必须存在于目标RBD映像中

2. 如果使用export-diff命令时指定了一个结束快照，则导入数据后在目标RBD镜像中创建相同的快照名称

### 导出和导入过程的管道

将破折号(-)字符指定为导出操作的目标文件将导致输出转到标准输出(stdout)。

还可以使用破折号字符(-)指定标准输出或标准输入(stdin)作为导出目标或导入源。可以将两个命令管道到一个命令中

```bash
[ceph: root@node /]# rbd export rbd/img1 - | rbd import - bup/img1
```

rbd merge-diff命令将两个连续增量的rbd export-diff镜像操作的输出合并到一个目标路径上。该命令一次只能处理两条增量路径

```bash
[ceph: root@node /]# rbd merge-diff first second merged 
```

要在一个命令中合并两个以上的连续增量路径，可以将一个rbd export-diff输出管道到另一个rbd export-diff命令。使用破折号字符(-)作为管道前的命令中的目标，并作为管道后的命令中的源。

例如，可以将三个增量差异合并到一个命令行上的单个合并目标中。前一个export-diff命令快照的结束时间必须等于后一个export -diff命令快照的开始时间

```bash
[ceph: root@node /]# rbd merge-diff first second - | rbd merge-diff - third merged
```

rbd merge-diff命令只支持stripe-count为1的rbd镜像


